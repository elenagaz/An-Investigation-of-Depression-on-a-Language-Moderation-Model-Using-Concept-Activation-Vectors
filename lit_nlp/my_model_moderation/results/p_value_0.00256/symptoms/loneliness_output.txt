C:\Users\elena\miniconda3\envs\lit-nlp2\python.exe C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\moderation_demo.py 
2024-08-07 16:44:40.013019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 16:44:40.014203: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-07 16:44:46.028308: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 16:44:46.029420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2024-08-07 16:44:46.030524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2024-08-07 16:44:46.031794: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2024-08-07 16:44:46.032917: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2024-08-07 16:44:46.033985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2024-08-07 16:44:46.035050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2024-08-07 16:44:46.036096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2024-08-07 16:44:46.036609: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
I0807 16:44:46.037207  1324 moderation_demo.py:73] Working directory: KoalaAI/Text-Moderation
2024-08-07 16:44:47.126670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaForSequenceClassification: ['deberta.embeddings.position_ids']
- This IS expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFDebertaForSequenceClassification were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaForSequenceClassification for predictions without further training.
I0807 16:44:50.901211  1324 dev_server.py:90] 
 (    (           
 )\ ) )\ )  *   ) 
(()/((()/(` )  /( 
 /(_))/(_))( )(_))
(_)) (_)) (_(_()) 
| |  |_ _||_   _| 
| |__ | |   | |   
|____|___|  |_|   


I0807 16:44:50.901211  1324 dev_server.py:91] Starting LIT server...
W0807 16:44:50.902217  1324 model.py:114] Unable to infer init spec for model 'ModerationModel'. Unable to infer a type for parameter 'model_name' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 16:44:50.902217  1324 dataset.py:154] Unable to infer init spec for dataset 'ModerationDataset'. Unable to infer a type for parameter 'file_path' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 16:44:50.909435  1324 dataset.py:154] Unable to infer init spec for dataset 'NoneDataset'. Unable to infer a type for parameter 'models' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
I0807 16:44:50.909435  1324 rouge_scorer.py:83] Using default tokenizer.
I0807 16:44:50.914426  1324 wsgi_serving.py:46] 

Starting Server on port 8081
You can navigate to http://127.0.0.1:8081


I0807 16:44:50.918388  1324 _internal.py:187] WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:8081
I0807 16:44:50.918388  1324 _internal.py:187] Press CTRL+C to quit
I0807 16:45:03.774057  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:03] "GET / HTTP/1.1" 200 -
I0807 16:45:03.794066  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:03] "GET / HTTP/1.1" 200 -
I0807 16:45:03.874082  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:03] "GET /main.js HTTP/1.1" 200 -
I0807 16:45:04.222170  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:04] "GET /static/favicon.png HTTP/1.1" 200 -
I0807 16:45:04.596695  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:04] "POST /get_info HTTP/1.1" 200 -
I0807 16:45:04.692936  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:04] "POST /get_dataset?dataset_name=moderation_dataset HTTP/1.1" 200 -
I0807 16:45:04.715176  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:45:04] "GET /static/onboarding_1_welcome.gif HTTP/1.1" 200 -
I0807 16:45:04.833312  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 16:45:04.834312  1324 caching.py:306] CachingModelWrapper 'moderation': 508 misses out of 508 inputs
I0807 16:45:04.835311  1324 moderation.py:316] -------------------------> using predict here
You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
I0807 16:46:10.950120  1324 moderation.py:316] -------------------------> using predict here
I0807 16:46:21.462165  1324 moderation.py:316] -------------------------> using predict here
I0807 16:46:33.779033  1324 moderation.py:316] -------------------------> using predict here
I0807 16:46:42.056736  1324 moderation.py:316] -------------------------> using predict here
I0807 16:48:23.356495  1324 moderation.py:316] -------------------------> using predict here
I0807 16:48:49.872218  1324 moderation.py:316] -------------------------> using predict here
I0807 16:49:35.240624  1324 moderation.py:316] -------------------------> using predict here
I0807 16:52:40.219588  1324 moderation.py:316] -------------------------> using predict here
I0807 16:53:42.739378  1324 moderation.py:316] -------------------------> using predict here
I0807 16:54:07.430832  1324 moderation.py:316] -------------------------> using predict here
I0807 16:54:28.450180  1324 moderation.py:316] -------------------------> using predict here
I0807 16:54:48.717770  1324 moderation.py:316] -------------------------> using predict here
I0807 16:54:56.290538  1324 caching.py:314] Received 508 predictions from model
I0807 16:54:56.392635  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:54:56] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=classification&do_predict=1 HTTP/1.1" 200 -
I0807 16:54:56.444044  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 16:54:56.445042  1324 projection.py:183] Projection request: instance key: frozenset({('proj_kw', frozenset({('n_components', 3)})), ('field_name', 'cls_emb'), ('model_name', 'moderation'), ('use_input', False)})
I0807 16:54:56.471173  1324 projection.py:163] Creating new projection instance on 508 points
I0807 16:54:56.488350  1324 umap.py:38] UMAP input x_train: (508, 768)
I0807 16:55:09.603986  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:55:09] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=umap&do_predict=1 HTTP/1.1" 200 -
I0807 16:55:09.612065  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 16:55:09.614066  1324 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 16:55:09.615066  1324 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 16:55:09.615066  1324 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 16:55:09.615066  1324 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 16:55:09.628066  1324 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 16:55:09.628066  1324 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 16:55:09.629066  1324 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 16:55:09.629066  1324 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 16:55:09.630066  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 16:55:09] "POST /get_metrics?model=moderation&dataset_name=moderation_dataset&metrics=multiclass,paired&do_predict=1 HTTP/1.1" 200 -
I0807 17:01:12.602132  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
W0807 17:01:12.611176  1324 caching.py:288] Attmepting to retrieve 2 (of 508) predictions from the cache where the cache key is None - this can be from a missing or empty example id. These will call model.predict() on this and subsequent calls.
I0807 17:01:12.612143  1324 caching.py:306] CachingModelWrapper 'moderation': 2 misses out of 508 inputs
I0807 17:01:12.613137  1324 moderation.py:316] -------------------------> using predict here
I0807 17:01:16.213873  1324 caching.py:314] Received 2 predictions from model
I0807 17:01:16.214882  1324 compare_predictions.py:57] Comparing of data
E0807 17:01:16.214882  1324 compare_predictions.py:14] Difference found at [0]/cls_emb (numpy arrays differ)
E0807 17:01:16.214882  1324 compare_predictions.py:14] Difference found at [0]/input_embs (numpy arrays differ)
E0807 17:01:16.215852  1324 compare_predictions.py:14] Difference found at [0]/layer_0/avg_emb (numpy arrays differ)
E0807 17:01:16.218036  1324 compare_predictions.py:14] Difference found at [0]/layer_1/avg_emb (numpy arrays differ)
E0807 17:01:16.219073  1324 compare_predictions.py:14] Difference found at [0]/layer_2/avg_emb (numpy arrays differ)
E0807 17:01:16.219073  1324 compare_predictions.py:14] Difference found at [0]/layer_3/avg_emb (numpy arrays differ)
E0807 17:01:16.220058  1324 compare_predictions.py:14] Difference found at [0]/layer_4/avg_emb (numpy arrays differ)
E0807 17:01:16.220058  1324 compare_predictions.py:14] Difference found at [0]/layer_5/avg_emb (numpy arrays differ)
E0807 17:01:16.220058  1324 compare_predictions.py:14] Difference found at [0]/layer_6/avg_emb (numpy arrays differ)
E0807 17:01:16.221048  1324 compare_predictions.py:14] Difference found at [0]/layer_7/avg_emb (numpy arrays differ)
E0807 17:01:16.221048  1324 compare_predictions.py:14] Difference found at [0]/layer_8/avg_emb (numpy arrays differ)
E0807 17:01:16.222061  1324 compare_predictions.py:14] Difference found at [0]/layer_9/avg_emb (numpy arrays differ)
E0807 17:01:16.222061  1324 compare_predictions.py:14] Difference found at [0]/layer_10/avg_emb (numpy arrays differ)
E0807 17:01:16.222061  1324 compare_predictions.py:14] Difference found at [0]/layer_11/avg_emb (numpy arrays differ)
E0807 17:01:16.223049  1324 compare_predictions.py:14] Difference found at [0]/layer_12/avg_emb (numpy arrays differ)
E0807 17:01:16.227048  1324 compare_predictions.py:14] Difference found at [0]/layer_1/attention (numpy arrays differ)
E0807 17:01:16.233041  1324 compare_predictions.py:14] Difference found at [0]/layer_2/attention (numpy arrays differ)
E0807 17:01:16.237048  1324 compare_predictions.py:14] Difference found at [0]/layer_3/attention (numpy arrays differ)
E0807 17:01:16.242056  1324 compare_predictions.py:14] Difference found at [0]/layer_4/attention (numpy arrays differ)
E0807 17:01:16.246167  1324 compare_predictions.py:14] Difference found at [0]/layer_5/attention (numpy arrays differ)
E0807 17:01:16.251179  1324 compare_predictions.py:14] Difference found at [0]/layer_6/attention (numpy arrays differ)
E0807 17:01:16.254179  1324 compare_predictions.py:14] Difference found at [0]/layer_7/attention (numpy arrays differ)
E0807 17:01:16.257179  1324 compare_predictions.py:14] Difference found at [0]/layer_8/attention (numpy arrays differ)
E0807 17:01:16.261178  1324 compare_predictions.py:14] Difference found at [0]/layer_9/attention (numpy arrays differ)
E0807 17:01:16.266562  1324 compare_predictions.py:14] Difference found at [0]/layer_10/attention (numpy arrays differ)
E0807 17:01:16.271599  1324 compare_predictions.py:14] Difference found at [0]/layer_11/attention (numpy arrays differ)
E0807 17:01:16.277690  1324 compare_predictions.py:14] Difference found at [0]/layer_12/attention (numpy arrays differ)
E0807 17:01:16.277690  1324 compare_predictions.py:14] Difference found at [0]/probas (numpy arrays differ)
E0807 17:01:16.282766  1324 compare_predictions.py:14] Difference found at [0]/cls_grad (numpy arrays differ)
E0807 17:01:16.285099  1324 compare_predictions.py:14] Difference found at [0]/token_grad_prompt (numpy arrays differ)
E0807 17:01:16.404626  1324 compare_predictions.py:14] Difference found at [5]/input_embs (numpy arrays differ)
E0807 17:01:16.410588  1324 compare_predictions.py:14] Difference found at [5]/probas (numpy arrays differ)
E0807 17:01:16.412631  1324 compare_predictions.py:14] Difference found at [5]/cls_grad (numpy arrays differ)
E0807 17:01:16.414669  1324 compare_predictions.py:14] Difference found at [5]/token_grad_prompt (numpy arrays differ)
I0807 17:01:21.068666  1324 tcav.py:359] Result:
I0807 17:01:21.068666  1324 tcav.py:361] 0.6470588235294118
I0807 17:01:21.068666  1324 tcav.py:362] Random Mean:
I0807 17:01:21.068666  1324 tcav.py:363] 0.4633986928104574
I0807 17:01:21.068666  1324 tcav.py:364] ----> p_value
I0807 17:01:21.068666  1324 tcav.py:365] 5.0809417378668925e-06
I0807 17:01:21.070815  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:01:21] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 17:01:34.558015  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
I0807 17:01:35.531680  1324 tcav.py:359] Result:
I0807 17:01:35.532653  1324 tcav.py:361] 0.59
I0807 17:01:35.532653  1324 tcav.py:362] Random Mean:
I0807 17:01:35.532653  1324 tcav.py:363] 0.48733333333333334
I0807 17:01:35.532653  1324 tcav.py:364] ----> p_value
I0807 17:01:35.532653  1324 tcav.py:365] 0.03230185604222196
I0807 17:01:35.630669  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:01:35] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 17:01:52.165120  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:01:53.124247  1324 tcav.py:359] Result:
I0807 17:01:53.124247  1324 tcav.py:361] 0.44339622641509435
I0807 17:01:53.124247  1324 tcav.py:362] Random Mean:
I0807 17:01:53.124247  1324 tcav.py:363] 0.4113207547169811
I0807 17:01:53.124247  1324 tcav.py:364] ----> p_value
I0807 17:01:53.124247  1324 tcav.py:365] 0.7407243656341573
I0807 17:01:53.217837  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:01:53] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 17:02:09.557190  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:02:10.507509  1324 tcav.py:359] Result:
I0807 17:02:10.507509  1324 tcav.py:361] 0.4
I0807 17:02:10.507509  1324 tcav.py:362] Random Mean:
I0807 17:02:10.507509  1324 tcav.py:363] 0.47333333333333333
I0807 17:02:10.507509  1324 tcav.py:364] ----> p_value
I0807 17:02:10.508501  1324 tcav.py:365] 0.8832636377148342
I0807 17:02:10.604130  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:02:10] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 17:02:20.068929  1324 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:02:21.047343  1324 tcav.py:359] Result:
I0807 17:02:21.047343  1324 tcav.py:361] 0.53
I0807 17:02:21.047343  1324 tcav.py:362] Random Mean:
I0807 17:02:21.047343  1324 tcav.py:363] 0.538
I0807 17:02:21.047343  1324 tcav.py:364] ----> p_value
I0807 17:02:21.047343  1324 tcav.py:365] 0.03779169728586889
I0807 17:02:21.165829  1324 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:02:21] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 17:03:09.610390  1324 moderation_demo.py:59] File C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\KoalaAI_Text-Moderation_prediction_cache.pkl deleted.

Process finished with exit code 0
