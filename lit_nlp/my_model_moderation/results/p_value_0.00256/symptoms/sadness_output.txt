C:\Users\elena\miniconda3\envs\lit-nlp2\python.exe C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\moderation_demo.py 
2024-08-07 18:25:46.278504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 18:25:46.279911: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-07 18:25:53.150731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 18:25:53.152554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2024-08-07 18:25:53.155923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2024-08-07 18:25:53.157990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2024-08-07 18:25:53.159920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2024-08-07 18:25:53.162404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2024-08-07 18:25:53.164326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2024-08-07 18:25:53.166477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2024-08-07 18:25:53.167114: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
I0807 18:25:53.168188 12416 moderation_demo.py:73] Working directory: KoalaAI/Text-Moderation
2024-08-07 18:25:54.674923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaForSequenceClassification: ['deberta.embeddings.position_ids']
- This IS expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFDebertaForSequenceClassification were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaForSequenceClassification for predictions without further training.
I0807 18:25:58.881083 12416 dev_server.py:90] 
 (    (           
 )\ ) )\ )  *   ) 
(()/((()/(` )  /( 
 /(_))/(_))( )(_))
(_)) (_)) (_(_()) 
| |  |_ _||_   _| 
| |__ | |   | |   
|____|___|  |_|   


I0807 18:25:58.881083 12416 dev_server.py:91] Starting LIT server...
W0807 18:25:58.882095 12416 model.py:114] Unable to infer init spec for model 'ModerationModel'. Unable to infer a type for parameter 'model_name' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 18:25:58.882095 12416 dataset.py:154] Unable to infer init spec for dataset 'ModerationDataset'. Unable to infer a type for parameter 'file_path' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 18:25:58.889077 12416 dataset.py:154] Unable to infer init spec for dataset 'NoneDataset'. Unable to infer a type for parameter 'models' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
I0807 18:25:58.889077 12416 rouge_scorer.py:83] Using default tokenizer.
I0807 18:25:58.894079 12416 wsgi_serving.py:46] 

Starting Server on port 8081
You can navigate to http://127.0.0.1:8081


I0807 18:25:58.905191 12416 _internal.py:187] WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:8081
I0807 18:25:58.905191 12416 _internal.py:187] Press CTRL+C to quit
I0807 18:26:29.388647 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:29] "GET / HTTP/1.1" 200 -
I0807 18:26:29.505419 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:29] "GET /main.js HTTP/1.1" 200 -
I0807 18:26:29.941581 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:29] "GET /static/favicon.png HTTP/1.1" 200 -
I0807 18:26:30.369402 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:30] "POST /get_info HTTP/1.1" 200 -
I0807 18:26:30.481830 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:30] "POST /get_dataset?dataset_name=moderation_dataset HTTP/1.1" 200 -
I0807 18:26:30.499956 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:26:30] "GET /static/onboarding_1_welcome.gif HTTP/1.1" 200 -
I0807 18:26:30.621090 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:26:30.623090 12416 caching.py:306] CachingModelWrapper 'moderation': 508 misses out of 508 inputs
I0807 18:26:30.623090 12416 moderation.py:316] -------------------------> using predict here
You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
I0807 18:26:49.801583 12416 moderation.py:316] -------------------------> using predict here
I0807 18:27:00.274246 12416 moderation.py:316] -------------------------> using predict here
I0807 18:27:12.708651 12416 moderation.py:316] -------------------------> using predict here
I0807 18:27:21.032513 12416 moderation.py:316] -------------------------> using predict here
I0807 18:29:11.715604 12416 moderation.py:316] -------------------------> using predict here
I0807 18:29:40.259294 12416 moderation.py:316] -------------------------> using predict here
I0807 18:30:24.321197 12416 moderation.py:316] -------------------------> using predict here
I0807 18:33:00.541934 12416 moderation.py:316] -------------------------> using predict here
I0807 18:34:05.170990 12416 moderation.py:316] -------------------------> using predict here
I0807 18:34:29.368566 12416 moderation.py:316] -------------------------> using predict here
I0807 18:34:49.264438 12416 moderation.py:316] -------------------------> using predict here
I0807 18:35:07.143088 12416 moderation.py:316] -------------------------> using predict here
I0807 18:35:16.176289 12416 caching.py:314] Received 508 predictions from model
I0807 18:35:16.303103 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:35:16] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=classification&do_predict=1 HTTP/1.1" 200 -
I0807 18:35:16.364194 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:35:16.367198 12416 projection.py:183] Projection request: instance key: frozenset({('field_name', 'cls_emb'), ('use_input', False), ('model_name', 'moderation'), ('proj_kw', frozenset({('n_components', 3)}))})
I0807 18:35:16.396192 12416 projection.py:163] Creating new projection instance on 508 points
I0807 18:35:16.415190 12416 umap.py:38] UMAP input x_train: (508, 768)
I0807 18:35:29.757783 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:35:29] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=umap&do_predict=1 HTTP/1.1" 200 -
I0807 18:35:29.765879 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:35:29.767879 12416 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 18:35:29.767879 12416 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 18:35:29.768878 12416 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 18:35:29.768878 12416 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 18:35:29.780877 12416 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 18:35:29.781878 12416 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 18:35:29.781878 12416 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 18:35:29.781878 12416 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 18:35:29.782878 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:35:29] "POST /get_metrics?model=moderation&dataset_name=moderation_dataset&metrics=multiclass,paired&do_predict=1 HTTP/1.1" 200 -
I0807 18:42:46.609636 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
W0807 18:42:46.621100 12416 caching.py:288] Attmepting to retrieve 1 (of 508) predictions from the cache where the cache key is None - this can be from a missing or empty example id. These will call model.predict() on this and subsequent calls.
I0807 18:42:46.621100 12416 caching.py:306] CachingModelWrapper 'moderation': 1 misses out of 508 inputs
I0807 18:42:46.622134 12416 moderation.py:316] -------------------------> using predict here
I0807 18:42:48.414184 12416 caching.py:314] Received 1 predictions from model
I0807 18:42:48.415185 12416 compare_predictions.py:57] Comparing of data
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/cls_emb (numpy arrays differ)
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/input_embs (numpy arrays differ)
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/layer_0/avg_emb (numpy arrays differ)
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/layer_1/avg_emb (numpy arrays differ)
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/layer_2/avg_emb (numpy arrays differ)
E0807 18:42:48.464263 12416 compare_predictions.py:14] Difference found at [3]/layer_3/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_4/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_5/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_6/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_7/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_8/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_9/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_10/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_11/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_12/avg_emb (numpy arrays differ)
E0807 18:42:48.465261 12416 compare_predictions.py:14] Difference found at [3]/layer_1/attention (numpy arrays differ)
E0807 18:42:48.466261 12416 compare_predictions.py:14] Difference found at [3]/layer_2/attention (numpy arrays differ)
E0807 18:42:48.466261 12416 compare_predictions.py:14] Difference found at [3]/layer_3/attention (numpy arrays differ)
E0807 18:42:48.467261 12416 compare_predictions.py:14] Difference found at [3]/layer_4/attention (numpy arrays differ)
E0807 18:42:48.468261 12416 compare_predictions.py:14] Difference found at [3]/layer_5/attention (numpy arrays differ)
E0807 18:42:48.468261 12416 compare_predictions.py:14] Difference found at [3]/layer_6/attention (numpy arrays differ)
E0807 18:42:48.470260 12416 compare_predictions.py:14] Difference found at [3]/layer_7/attention (numpy arrays differ)
E0807 18:42:48.470260 12416 compare_predictions.py:14] Difference found at [3]/layer_8/attention (numpy arrays differ)
E0807 18:42:48.471262 12416 compare_predictions.py:14] Difference found at [3]/layer_9/attention (numpy arrays differ)
E0807 18:42:48.472261 12416 compare_predictions.py:14] Difference found at [3]/layer_10/attention (numpy arrays differ)
E0807 18:42:48.473281 12416 compare_predictions.py:14] Difference found at [3]/layer_11/attention (numpy arrays differ)
E0807 18:42:48.474280 12416 compare_predictions.py:14] Difference found at [3]/layer_12/attention (numpy arrays differ)
E0807 18:42:48.474280 12416 compare_predictions.py:14] Difference found at [3]/probas (numpy arrays differ)
E0807 18:42:48.476262 12416 compare_predictions.py:14] Difference found at [3]/cls_grad (numpy arrays differ)
E0807 18:42:48.478277 12416 compare_predictions.py:14] Difference found at [3]/token_grad_prompt (numpy arrays differ)
I0807 18:42:53.438028 12416 tcav.py:359] Result:
I0807 18:42:53.439041 12416 tcav.py:361] 0.6039603960396039
I0807 18:42:53.439297 12416 tcav.py:362] Random Mean:
I0807 18:42:53.439297 12416 tcav.py:363] 0.5102310231023102
I0807 18:42:53.439528 12416 tcav.py:364] ----> p_value
I0807 18:42:53.439528 12416 tcav.py:365] 0.002049317601172165
I0807 18:42:53.442592 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:42:53] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:43:11.867404 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:43:12.812690 12416 tcav.py:359] Result:
I0807 18:43:12.812690 12416 tcav.py:361] 0.52
I0807 18:43:12.812690 12416 tcav.py:362] Random Mean:
I0807 18:43:12.812690 12416 tcav.py:363] 0.5166666666666667
I0807 18:43:12.813695 12416 tcav.py:364] ----> p_value
I0807 18:43:12.813695 12416 tcav.py:365] 0.6129073565960559
I0807 18:43:12.914249 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:43:12] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:43:22.824908 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:43:23.781493 12416 tcav.py:359] Result:
I0807 18:43:23.782563 12416 tcav.py:361] 0.2616822429906542
I0807 18:43:23.782563 12416 tcav.py:362] Random Mean:
I0807 18:43:23.782563 12416 tcav.py:363] 0.4604361370716511
I0807 18:43:23.782563 12416 tcav.py:364] ----> p_value
I0807 18:43:23.782563 12416 tcav.py:365] 0.7863447782616666
I0807 18:43:23.890600 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:43:23] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:43:45.416977 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:43:46.377040 12416 tcav.py:359] Result:
I0807 18:43:46.377274 12416 tcav.py:361] 0.51
I0807 18:43:46.377274 12416 tcav.py:362] Random Mean:
I0807 18:43:46.377274 12416 tcav.py:363] 0.48733333333333334
I0807 18:43:46.377274 12416 tcav.py:364] ----> p_value
I0807 18:43:46.377274 12416 tcav.py:365] 0.046609759843225004
I0807 18:43:46.480527 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:43:46] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:43:56.754223 12416 app.py:205] 508 of 508 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:43:57.638974 12416 tcav.py:359] Result:
I0807 18:43:57.640037 12416 tcav.py:361] 0.75
I0807 18:43:57.640037 12416 tcav.py:362] Random Mean:
I0807 18:43:57.640037 12416 tcav.py:363] 0.47333333333333333
I0807 18:43:57.640037 12416 tcav.py:364] ----> p_value
I0807 18:43:57.640037 12416 tcav.py:365] 0.0002743133136790107
I0807 18:43:57.736467 12416 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:43:57] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:44:53.861342 12416 moderation_demo.py:59] File C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\KoalaAI_Text-Moderation_prediction_cache.pkl deleted.

Process finished with exit code 0
