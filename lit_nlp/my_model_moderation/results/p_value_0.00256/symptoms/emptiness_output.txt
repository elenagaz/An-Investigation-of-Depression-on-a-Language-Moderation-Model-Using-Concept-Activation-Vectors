C:\Users\elena\miniconda3\envs\lit-nlp2\python.exe C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\moderation_demo.py 
2024-08-07 13:19:46.527530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 13:19:46.528567: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-07 13:19:53.100485: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 13:19:53.101606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2024-08-07 13:19:53.102650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2024-08-07 13:19:53.103730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2024-08-07 13:19:53.104732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2024-08-07 13:19:53.105873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2024-08-07 13:19:53.106999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2024-08-07 13:19:53.108073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2024-08-07 13:19:53.108477: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
I0807 13:19:53.109279  1548 moderation_demo.py:73] Working directory: KoalaAI/Text-Moderation
2024-08-07 13:19:54.512706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaForSequenceClassification: ['deberta.embeddings.position_ids']
- This IS expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFDebertaForSequenceClassification were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaForSequenceClassification for predictions without further training.
I0807 13:19:59.155768  1548 dev_server.py:90] 
 (    (           
 )\ ) )\ )  *   ) 
(()/((()/(` )  /( 
 /(_))/(_))( )(_))
(_)) (_)) (_(_()) 
| |  |_ _||_   _| 
| |__ | |   | |   
|____|___|  |_|   


I0807 13:19:59.155768  1548 dev_server.py:91] Starting LIT server...
W0807 13:19:59.156769  1548 model.py:114] Unable to infer init spec for model 'ModerationModel'. Unable to infer a type for parameter 'model_name' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 13:19:59.156769  1548 dataset.py:154] Unable to infer init spec for dataset 'ModerationDataset'. Unable to infer a type for parameter 'file_path' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 13:19:59.164766  1548 dataset.py:154] Unable to infer init spec for dataset 'NoneDataset'. Unable to infer a type for parameter 'models' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
I0807 13:19:59.165768  1548 rouge_scorer.py:83] Using default tokenizer.
I0807 13:19:59.171775  1548 wsgi_serving.py:46] 

Starting Server on port 8081
You can navigate to http://127.0.0.1:8081


I0807 13:19:59.181769  1548 _internal.py:187] WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:8081
I0807 13:19:59.181769  1548 _internal.py:187] Press CTRL+C to quit
I0807 13:20:02.561237  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:02] "GET / HTTP/1.1" 200 -
I0807 13:20:02.716532  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:02] "GET /main.js HTTP/1.1" 200 -
I0807 13:20:03.235008  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:03] "GET /static/favicon.png HTTP/1.1" 200 -
I0807 13:20:04.039721  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:04] "POST /get_info HTTP/1.1" 200 -
I0807 13:20:04.260919  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:04] "POST /get_dataset?dataset_name=moderation_dataset HTTP/1.1" 200 -
I0807 13:20:04.280126  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:20:04] "GET /static/onboarding_1_welcome.gif HTTP/1.1" 200 -
I0807 13:20:04.450127  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:20:04.452127  1548 caching.py:306] CachingModelWrapper 'moderation': 507 misses out of 507 inputs
I0807 13:20:04.453125  1548 moderation.py:316] -------------------------> using predict here
You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
I0807 13:22:10.286295  1548 moderation.py:316] -------------------------> using predict here
I0807 13:22:22.895004  1548 moderation.py:316] -------------------------> using predict here
I0807 13:22:36.166613  1548 moderation.py:316] -------------------------> using predict here
I0807 13:22:45.103539  1548 moderation.py:316] -------------------------> using predict here
I0807 13:24:25.409861  1548 moderation.py:316] -------------------------> using predict here
I0807 13:24:54.202647  1548 moderation.py:316] -------------------------> using predict here
I0807 13:25:41.975993  1548 moderation.py:316] -------------------------> using predict here
I0807 13:29:01.097680  1548 moderation.py:316] -------------------------> using predict here
I0807 13:29:24.254425  1548 moderation.py:316] -------------------------> using predict here
I0807 13:29:48.041852  1548 moderation.py:316] -------------------------> using predict here
I0807 13:30:08.733860  1548 moderation.py:316] -------------------------> using predict here
I0807 13:30:28.050894  1548 moderation.py:316] -------------------------> using predict here
I0807 13:30:36.006622  1548 caching.py:314] Received 507 predictions from model
I0807 13:30:36.093606  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:30:36] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=classification&do_predict=1 HTTP/1.1" 200 -
I0807 13:30:36.161614  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:30:36.164052  1548 projection.py:183] Projection request: instance key: frozenset({('model_name', 'moderation'), ('use_input', False), ('field_name', 'cls_emb'), ('proj_kw', frozenset({('n_components', 3)}))})
I0807 13:30:36.203155  1548 projection.py:163] Creating new projection instance on 507 points
I0807 13:30:36.217530  1548 umap.py:38] UMAP input x_train: (507, 768)
I0807 13:30:48.396011  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:30:48] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=umap&do_predict=1 HTTP/1.1" 200 -
I0807 13:30:48.412069  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:30:48.415071  1548 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 13:30:48.415071  1548 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 13:30:48.416073  1548 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 13:30:48.416073  1548 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 13:30:48.428136  1548 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 13:30:48.428136  1548 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 13:30:48.428136  1548 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 13:30:48.428136  1548 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 13:30:48.430193  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:30:48] "POST /get_metrics?model=moderation&dataset_name=moderation_dataset&metrics=multiclass,paired&do_predict=1 HTTP/1.1" 200 -
I0807 13:34:39.474189  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
W0807 13:34:39.484401  1548 caching.py:288] Attmepting to retrieve 2 (of 507) predictions from the cache where the cache key is None - this can be from a missing or empty example id. These will call model.predict() on this and subsequent calls.
I0807 13:34:39.485464  1548 caching.py:306] CachingModelWrapper 'moderation': 2 misses out of 507 inputs
I0807 13:34:39.485464  1548 moderation.py:316] -------------------------> using predict here
I0807 13:34:44.394850  1548 caching.py:314] Received 2 predictions from model
I0807 13:34:44.394850  1548 compare_predictions.py:57] Comparing of data
E0807 13:34:44.499643  1548 compare_predictions.py:14] Difference found at [0]/probas (numpy arrays differ)
E0807 13:34:44.505700  1548 compare_predictions.py:14] Difference found at [0]/cls_grad (numpy arrays differ)
E0807 13:34:44.507742  1548 compare_predictions.py:14] Difference found at [0]/token_grad_prompt (numpy arrays differ)
E0807 13:34:44.524687  1548 compare_predictions.py:14] Difference found at [1]/probas (numpy arrays differ)
E0807 13:34:44.525686  1548 compare_predictions.py:14] Difference found at [1]/cls_grad (numpy arrays differ)
E0807 13:34:44.527072  1548 compare_predictions.py:14] Difference found at [1]/token_grad_prompt (numpy arrays differ)
I0807 13:34:49.266025  1548 tcav.py:359] Result:
I0807 13:34:49.266025  1548 tcav.py:361] 0.7843137254901961
I0807 13:34:49.267015  1548 tcav.py:362] Random Mean:
I0807 13:34:49.267015  1548 tcav.py:363] 0.4241830065359478
I0807 13:34:49.267015  1548 tcav.py:364] ----> p_value
I0807 13:34:49.267015  1548 tcav.py:365] 2.4296749201504216e-07
I0807 13:34:49.269203  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:34:49] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 13:35:07.549974  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:35:08.592514  1548 tcav.py:359] Result:
I0807 13:35:08.593513  1548 tcav.py:361] 0.59
I0807 13:35:08.593513  1548 tcav.py:362] Random Mean:
I0807 13:35:08.593513  1548 tcav.py:363] 0.47800000000000004
I0807 13:35:08.593513  1548 tcav.py:364] ----> p_value
I0807 13:35:08.593513  1548 tcav.py:365] 0.1034817099233862
I0807 13:35:08.699814  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:35:08] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 13:35:17.367066  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:35:18.364303  1548 tcav.py:359] Result:
I0807 13:35:18.365349  1548 tcav.py:361] 0.7333333333333333
I0807 13:35:18.365349  1548 tcav.py:362] Random Mean:
I0807 13:35:18.365349  1548 tcav.py:363] 0.5174603174603175
I0807 13:35:18.365349  1548 tcav.py:364] ----> p_value
I0807 13:35:18.365349  1548 tcav.py:365] 0.2673926042332215
I0807 13:35:18.464739  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:35:18] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 13:35:22.142105  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:35:23.067899  1548 tcav.py:359] Result:
I0807 13:35:23.067899  1548 tcav.py:361] 0.53
I0807 13:35:23.067899  1548 tcav.py:362] Random Mean:
I0807 13:35:23.068884  1548 tcav.py:363] 0.46933333333333327
I0807 13:35:23.068884  1548 tcav.py:364] ----> p_value
I0807 13:35:23.068884  1548 tcav.py:365] 0.03673041130095102
I0807 13:35:23.166768  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:35:23] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 13:35:27.862953  1548 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 13:35:28.824778  1548 tcav.py:359] Result:
I0807 13:35:28.824778  1548 tcav.py:361] 0.6
I0807 13:35:28.824778  1548 tcav.py:362] Random Mean:
I0807 13:35:28.824778  1548 tcav.py:363] 0.4226666666666665
I0807 13:35:28.824778  1548 tcav.py:364] ----> p_value
I0807 13:35:28.824778  1548 tcav.py:365] 1.7901744080243933e-05
I0807 13:35:28.923134  1548 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 13:35:28] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
