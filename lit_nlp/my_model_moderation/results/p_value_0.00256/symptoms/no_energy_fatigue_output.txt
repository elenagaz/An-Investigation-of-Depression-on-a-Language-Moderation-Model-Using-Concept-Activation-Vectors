C:\Users\elena\miniconda3\envs\lit-nlp2\python.exe C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\moderation_demo.py 
2024-08-07 17:34:52.790129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 17:34:52.790959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-07 17:34:58.540211: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2024-08-07 17:34:58.541222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2024-08-07 17:34:58.542177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2024-08-07 17:34:58.543174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2024-08-07 17:34:58.544167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2024-08-07 17:34:58.545237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2024-08-07 17:34:58.546339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2024-08-07 17:34:58.547352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2024-08-07 17:34:58.547759: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
I0807 17:34:58.548740  7304 moderation_demo.py:73] Working directory: KoalaAI/Text-Moderation
2024-08-07 17:34:59.715188: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaForSequenceClassification: ['deberta.embeddings.position_ids']
- This IS expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDebertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFDebertaForSequenceClassification were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaForSequenceClassification for predictions without further training.
I0807 17:35:03.482959  7304 dev_server.py:90] 
 (    (           
 )\ ) )\ )  *   ) 
(()/((()/(` )  /( 
 /(_))/(_))( )(_))
(_)) (_)) (_(_()) 
| |  |_ _||_   _| 
| |__ | |   | |   
|____|___|  |_|   


I0807 17:35:03.482959  7304 dev_server.py:91] Starting LIT server...
W0807 17:35:03.483958  7304 model.py:114] Unable to infer init spec for model 'ModerationModel'. Unable to infer a type for parameter 'model_name' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 17:35:03.483958  7304 dataset.py:154] Unable to infer init spec for dataset 'ModerationDataset'. Unable to infer a type for parameter 'file_path' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
W0807 17:35:03.489932  7304 dataset.py:154] Unable to infer init spec for dataset 'NoneDataset'. Unable to infer a type for parameter 'models' of '__init__'. Please add a type hint or default value, or implement a Spec literal.
I0807 17:35:03.489932  7304 rouge_scorer.py:83] Using default tokenizer.
I0807 17:35:03.493932  7304 wsgi_serving.py:46] 

Starting Server on port 8081
You can navigate to http://127.0.0.1:8081


I0807 17:35:03.504931  7304 _internal.py:187] WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:8081
I0807 17:35:03.505922  7304 _internal.py:187] Press CTRL+C to quit
I0807 17:35:13.456409  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:35:13] "POST /get_info HTTP/1.1" 200 -
I0807 17:35:13.621562  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:35:13] "POST /get_dataset?dataset_name=moderation_dataset HTTP/1.1" 200 -
I0807 17:35:13.715086  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:35:13.716084  7304 caching.py:306] CachingModelWrapper 'moderation': 507 misses out of 507 inputs
I0807 17:35:13.717089  7304 moderation.py:316] -------------------------> using predict here
You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
I0807 17:37:23.852915  7304 moderation.py:316] -------------------------> using predict here
I0807 17:37:34.261480  7304 moderation.py:316] -------------------------> using predict here
I0807 17:37:46.456213  7304 moderation.py:316] -------------------------> using predict here
I0807 17:37:54.661011  7304 moderation.py:316] -------------------------> using predict here
I0807 17:39:33.302098  7304 moderation.py:316] -------------------------> using predict here
I0807 17:40:04.200750  7304 moderation.py:316] -------------------------> using predict here
I0807 17:40:51.392049  7304 moderation.py:316] -------------------------> using predict here
I0807 17:43:59.031974  7304 moderation.py:316] -------------------------> using predict here
I0807 17:44:22.188198  7304 moderation.py:316] -------------------------> using predict here
I0807 17:44:44.360752  7304 moderation.py:316] -------------------------> using predict here
I0807 17:45:03.845417  7304 moderation.py:316] -------------------------> using predict here
I0807 17:45:24.808470  7304 moderation.py:316] -------------------------> using predict here
I0807 17:45:32.125265  7304 caching.py:314] Received 507 predictions from model
I0807 17:45:32.191681  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:45:32] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=classification&do_predict=1 HTTP/1.1" 200 -
I0807 17:45:32.215633  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:45:32.216644  7304 projection.py:183] Projection request: instance key: frozenset({('field_name', 'cls_emb'), ('use_input', False), ('proj_kw', frozenset({('n_components', 3)})), ('model_name', 'moderation')})
I0807 17:45:32.235395  7304 projection.py:163] Creating new projection instance on 507 points
I0807 17:45:32.249839  7304 umap.py:38] UMAP input x_train: (507, 768)
I0807 17:45:43.936396  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:45:43] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=umap&do_predict=1 HTTP/1.1" 200 -
I0807 17:45:43.942469  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 17:45:43.944468  7304 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 17:45:43.944468  7304 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 17:45:43.945469  7304 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 17:45:43.945469  7304 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 17:45:43.957469  7304 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 17:45:43.958469  7304 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 17:45:43.958469  7304 metrics.py:56] Skipping 'tokens': No parent provided.
I0807 17:45:43.958469  7304 metrics.py:71] Skipping 'tokens_prompt': incompatible parent 'prompt'.
I0807 17:45:43.960469  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 17:45:43] "POST /get_metrics?model=moderation&dataset_name=moderation_dataset&metrics=multiclass,paired&do_predict=1 HTTP/1.1" 200 -
I0807 18:22:09.237011  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
W0807 18:22:09.246009  7304 caching.py:288] Attmepting to retrieve 1 (of 507) predictions from the cache where the cache key is None - this can be from a missing or empty example id. These will call model.predict() on this and subsequent calls.
I0807 18:22:09.247010  7304 caching.py:306] CachingModelWrapper 'moderation': 1 misses out of 507 inputs
I0807 18:22:09.247010  7304 moderation.py:316] -------------------------> using predict here
I0807 18:22:14.025429  7304 caching.py:314] Received 1 predictions from model
I0807 18:22:14.025429  7304 compare_predictions.py:57] Comparing of data
E0807 18:22:14.134523  7304 compare_predictions.py:14] Difference found at [1]/probas (numpy arrays differ)
E0807 18:22:14.139505  7304 compare_predictions.py:14] Difference found at [1]/cls_grad (numpy arrays differ)
E0807 18:22:14.143505  7304 compare_predictions.py:14] Difference found at [1]/token_grad_prompt (numpy arrays differ)
I0807 18:22:19.250788  7304 tcav.py:359] Result:
I0807 18:22:19.250788  7304 tcav.py:361] 0.48514851485148514
I0807 18:22:19.250788  7304 tcav.py:362] Random Mean:
I0807 18:22:19.250788  7304 tcav.py:363] 0.4759075907590759
I0807 18:22:19.250788  7304 tcav.py:364] ----> p_value
I0807 18:22:19.250788  7304 tcav.py:365] 0.008592796006299103
I0807 18:22:19.256786  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:22:19] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:22:34.517743  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:22:36.452024  7304 tcav.py:359] Result:
I0807 18:22:36.452024  7304 tcav.py:361] 0.56
I0807 18:22:36.453023  7304 tcav.py:362] Random Mean:
I0807 18:22:36.453023  7304 tcav.py:363] 0.45666666666666667
I0807 18:22:36.453023  7304 tcav.py:364] ----> p_value
I0807 18:22:36.453023  7304 tcav.py:365] 0.037548823055947485
I0807 18:22:36.604995  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:22:36] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:22:44.018367  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:22:45.880535  7304 tcav.py:359] Result:
I0807 18:22:45.880535  7304 tcav.py:361] 0.39622641509433965
I0807 18:22:45.880535  7304 tcav.py:362] Random Mean:
I0807 18:22:45.881535  7304 tcav.py:363] 0.5113207547169811
I0807 18:22:45.881535  7304 tcav.py:364] ----> p_value
I0807 18:22:45.881535  7304 tcav.py:365] 0.5986726762555985
I0807 18:22:46.053032  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:22:46] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:22:51.578729  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
I0807 18:22:53.250688  7304 tcav.py:359] Result:
I0807 18:22:53.250688  7304 tcav.py:361] 0.48
I0807 18:22:53.250688  7304 tcav.py:362] Random Mean:
I0807 18:22:53.250688  7304 tcav.py:363] 0.5646666666666669
I0807 18:22:53.251687  7304 tcav.py:364] ----> p_value
I0807 18:22:53.251687  7304 tcav.py:365] 0.41822490396207346
I0807 18:22:53.463327  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:22:53] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:22:57.771233  7304 app.py:205] 507 of 507 inputs sent as IDs; reconstituting from dataset 'moderation_dataset'
Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
I0807 18:22:59.426595  7304 tcav.py:359] Result:
I0807 18:22:59.426595  7304 tcav.py:361] 0.56
I0807 18:22:59.426595  7304 tcav.py:362] Random Mean:
I0807 18:22:59.426595  7304 tcav.py:363] 0.5073333333333333
I0807 18:22:59.426595  7304 tcav.py:364] ----> p_value
I0807 18:22:59.426595  7304 tcav.py:365] 0.25131409224976725
I0807 18:22:59.575889  7304 _internal.py:187] 127.0.0.1 - - [07/Aug/2024 18:22:59] "POST /get_interpretations?model=moderation&dataset_name=moderation_dataset&interpreter=tcav&do_predict=1 HTTP/1.1" 200 -
I0807 18:23:44.166941  7304 moderation_demo.py:59] File C:\Users\elena\PycharmProjects\lit_bachelor\lit_nlp\examples\my_model_moderation\KoalaAI_Text-Moderation_prediction_cache.pkl deleted.

Process finished with exit code 0
